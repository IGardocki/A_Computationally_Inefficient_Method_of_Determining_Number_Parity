{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vlf15eknwa3m"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "# install tensorflow_cpu! Your code here.\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate training data\n",
        "num_samples = 1000000\n",
        "X = np.random.randint(-2147483648, 2147483647, num_samples)\n",
        "# your code here! Create labels for the data (call it y)\n",
        "# yopur code here! Let's check the shapes of X and y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0gQq9sL11nK",
        "outputId": "d5f0651e-2223-4049-9a97-713ce1131653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000000,)\n",
            "(1000000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization means adjusting the data so that it has a mean of 0 and a standard deviation of 1.\n",
        "# This is important for machine learning algorithms that are sensitive to the scale of the data (like gradient descent-based algorithms or distance-based algorithms).\n",
        "# When you apply StandardScaler() to your data, it transforms the data by subtracting the mean\n",
        "# and dividing by the standard deviation for each feature (column) in your dataset."
      ],
      "metadata": {
        "id": "TaRKxt79SaO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Your code here! Create an instance of StandardScaler.\n",
        "# Use the fit_transform method on X below\n",
        "X_scaled = scaler.<your_code_here>(X.reshape(-1, 1))  # Reshaping for scaler"
      ],
      "metadata": {
        "id": "h5UhpWxepEce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# below, use train_test_split with a test size of 0.2 and random state of 42\n",
        "X_train, X_test, y_train, y_test = #your_code_here"
      ],
      "metadata": {
        "id": "sP54PQqElGDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "\n",
        "def classification_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(1,)))\n",
        "    # Your code here! Add a dense layer of 64 with relu activation\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "GbGOzDk0A-b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here! instantiate our model. Call it model.\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "DCWPA25UqDrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code below! Use model.fit to train the model for 10 epochs\n",
        "model.<your_code_here>(X_train, y_train, validation_data=(X_test, y_test), epochs=<your_code_here>, verbose=2)"
      ],
      "metadata": {
        "id": "nTo1D9XhzwYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "# Your code below! Use model.evaluate to see the models acc and loss\n",
        "loss, accuracy = model.<your_code_here>(X_test, y_test)\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "7nBNQRGn4gfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "# Your code below! use model.predict to predict labels for the array of numbers\n",
        "predictions = model.<your_code_here>(np.array([1000001, 3, 1000000, 15]))\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "print(f\"Predictions: {predicted_labels.flatten()}\")"
      ],
      "metadata": {
        "id": "-amRiGz24gxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.42.1 -U"
      ],
      "metadata": {
        "id": "OHLaDzexkiKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Selecting the model. You will be using \"facebook/blenderbot-400M-distill\" in this example.\n",
        "model_name = \"facebook/blenderbot-400M-distill\"\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "DTHHP5VQyJo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the chat function\n",
        "def chat_with_bot():\n",
        "    while True:\n",
        "        # Get user input\n",
        "        input_text = input(\"You: \")\n",
        "\n",
        "        # Exit conditions\n",
        "        if input_text.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Tokenize input and generate response\n",
        "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "        outputs = model.generate(inputs, max_new_tokens=150)\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "        # Display bot's response\n",
        "        print(\"Chatbot:\", response)\n",
        "\n",
        "# Start chatting\n",
        "#your code here! Call the above function to chat with the bot. Play around with it a bit."
      ],
      "metadata": {
        "id": "r90KXSA0yPeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_bot_if_number_is_odd_or_even(num):\n",
        "  input_text = f'Is the number {num} even or odd?'\n",
        "\n",
        "  inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "  outputs = model.generate(inputs, max_new_tokens=150)\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "  return response"
      ],
      "metadata": {
        "id": "IoKYvh0o2uFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here! Use the above function to ask the bot if a number is odd or even. Then print the response."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1493WD8t7M1s",
        "outputId": "b28b23dc-e445-4bca-9ad6-dc5a26a3db7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No, it's not odd at all. It's the same number as my dog's name.\n"
          ]
        }
      ]
    }
  ]
}